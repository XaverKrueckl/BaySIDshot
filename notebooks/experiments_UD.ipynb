{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVcOCrPFZyNq"
   },
   "source": [
    "# A Notebook for Basic Auxiliary Task Experiments on UD Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 25869,
     "status": "ok",
     "timestamp": 1718097214860,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "U-rXwrPTI-Mh",
    "outputId": "b77ffb68-faec-4ddb-cfac-2a97720997ef"
   },
   "outputs": [],
   "source": [
    "# mount google drive for access to unpublished data and saving results!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# check if drive is present in root directory '/content'\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 40545,
     "status": "ok",
     "timestamp": 1718106495130,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "dcr3N0fjTUxa",
    "outputId": "e8fdeb8a-14f0-4d31-fd1a-3e3589e9777b"
   },
   "outputs": [],
   "source": [
    "# prepare/clear drive directory\n",
    "%rm -r /content/BaySIDshot # should fail in initial call\n",
    "%cd /content\n",
    "# get a fresh clone of BaySIDshot repo with it's submodules\n",
    "! git clone https://github.com/XaverKrueckl/BaySIDshot.git --recurse-submodules\n",
    "# cd into BaySIDshot repo:\n",
    "%cd /content/BaySIDshot/\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# prepare UD data to use with machamp:\n",
    "# again move into BaySIDshot repo to be safe:\n",
    "%cd /content/BaySIDshot/\n",
    "%ls -l\n",
    "%pwd\n",
    "\n",
    "! bash /content/BaySIDshot/scripts/prepare_ud_data.sh\n",
    "\n",
    "# finally move into machamp to start training and predictions\n",
    "%cd /content/BaySIDshot/machamp\n",
    "%ls -l\n",
    "%pwd"
   ],
   "metadata": {
    "id": "wJQLHAe8MbVS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718106501075,
     "user_tz": -120,
     "elapsed": 5955,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "ef0f6486-3fff-4d08-c390-791afbb1673b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Checks:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1718097286867,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "2RKo24KwfZZ3",
    "outputId": "43effe0e-2351-4746-f052-0b8f7a0c4b65"
   },
   "outputs": [],
   "source": [
    "# make sure to have a GPU backend selected\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 124363,
     "status": "ok",
     "timestamp": 1718097415728,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "Er1X18YZaSOd",
    "outputId": "33b3750e-2b65-4781-aaa1-10767a5cff78"
   },
   "outputs": [],
   "source": [
    "# install the required packages for machamp\n",
    "#! cat /content/BaySIDshot/machamp/README.md | grep \"requirements\"\n",
    "\n",
    "%cd /content/BaySIDshot/machamp\n",
    "! pip3 install --user -r /content/BaySIDshot/machamp/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6256,
     "status": "ok",
     "timestamp": 1718106507326,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "QyQgq3dNmZuP",
    "outputId": "81ffd828-08b2-485f-d840-4282b0459fac"
   },
   "outputs": [],
   "source": [
    "# appends the directory /root/.local/bin to the existing PATH variable,\n",
    "# allowing executables located in that directory to be run from anywhere in the shell\n",
    "! export PATH=$PATH:/root/.local/bin\n",
    "\n",
    "# check if imports for machamp are there\n",
    "import tensorflow as tf\n",
    "# check the version\n",
    "print(tf.__version__)\n",
    "\n",
    "# check if basic system works\n",
    "! python3 /content/BaySIDshot/machamp/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare evaluation data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!bash /content/BaySIDshot/scripts/prepare_evaldata_dialects.sh\n",
    "#!bash /content/BaySIDshot/scripts/prepare_evaldata_baseline.sh\n",
    "!bash /content/BaySIDshot/scripts/prepare_evaldata_alllangs.sh\n",
    "\n",
    "# if issues occur, use manually created gold set:\n",
    "# /content/BaySIDshot/manual_data/alllangs_eval_data # or just dialects_eval_data, etc.\n",
    "\n",
    "%cd /content/BaySIDshot/machamp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Multitask UDxNLU setting:\n"
   ],
   "metadata": {
    "id": "cmnDDw75m-VN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1718097426251,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "Ep39dLom-5Qu",
    "outputId": "837909f8-4034-4042-9b79-49f4ffdc908d"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/ud_nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# train experiment - make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp1_udnlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/ud_nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --device 0 --name mDeBERTa_exp1_udnlu_1234 --seed 1234"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jplou8H7nCKp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718105418988,
     "user_tz": -120,
     "elapsed": 141738,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "455bc307-3001-4f93-eab3-3dfd4b052c4f",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# save logs dir with model and metrics to drive\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/*_1234 /content/drive/MyDrive/Masterarbeit"
   ],
   "metadata": {
    "id": "DdmTUmn0nPMK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp1_udnlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "pViiXBJHjv3e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718105939773,
     "user_tz": -120,
     "elapsed": 61787,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "a9dd5674-dfce-4dc8-c361-1d98c4be4b2d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Sequential Intermediate UD_NLU setting:"
   ],
   "metadata": {
    "id": "nFL2LyXpRBjC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/ud_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ],
   "metadata": {
    "id": "8kXx9V2DtKB7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718106547092,
     "user_tz": -120,
     "elapsed": 1084,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "62acdb18-43cd-4cca-b398-61dbab1e9bb4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "g-IQ2moIuvx_",
    "outputId": "4633299e-4150-4595-e2e0-c46044de7af1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718114804019,
     "user_tz": -120,
     "elapsed": 339093,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    }
   },
   "outputs": [],
   "source": [
    "# train experiment - make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp1_ud_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/ud_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json  --sequential --device 0 --name mDeBERTa_exp1_ud_nlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWg1Ea04J3qA"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of logs dir accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp1_ud_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfye40NkJ43_",
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718114876504,
     "user_tz": -120,
     "elapsed": 62473,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "224809a5-c277-4c14-b1e3-9980a37153da"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp1_ud_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhcUQ7_A1y0t"
   },
   "source": [
    "### Reference for _MaChAmp_ and UD Data:\n",
    "\n",
    "```\n",
    "@inproceedings{van-der-goot-etal-2021-massive,\n",
    "    title = \"Massive Choice, Ample Tasks ({M}a{C}h{A}mp): A Toolkit for Multi-task Learning in {NLP}\",\n",
    "    author = {van der Goot, Rob  and\n",
    "      {\\\"U}st{\\\"u}n, Ahmet  and\n",
    "      Ramponi, Alan  and\n",
    "      Sharaf, Ibrahim  and\n",
    "      Plank, Barbara},\n",
    "    booktitle = \"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations\",\n",
    "    month = apr,\n",
    "    year = \"2021\",\n",
    "    address = \"Online\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2021.eacl-demos.22\",\n",
    "    doi = \"10.18653/v1/2021.eacl-demos.22\",\n",
    "    pages = \"176--197\",\n",
    "    abstract = \"Transfer learning, particularly approaches that combine multi-task learning with pre-trained contextualized embeddings and fine-tuning, have advanced the field of Natural Language Processing tremendously in recent years. In this paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized embeddings in multi-task settings. The benefits of MaChAmp are its flexible configuration options, and the support of a variety of natural language processing tasks in a uniform toolkit, from text classification and sequence labeling to dependency parsing, masked language modeling, and text generation.\",\n",
    "}\n",
    "@inproceedings{blaschke-etal-2024-maibaam,\n",
    "    title = \"{M}ai{B}aam: A Multi-Dialectal {B}avarian {U}niversal {D}ependency Treebank\",\n",
    "    author = {Blaschke, Verena  and\n",
    "      Kova{\\v{c}}i{\\'c}, Barbara  and\n",
    "      Peng, Siyao  and\n",
    "      Sch{\\\"u}tze, Hinrich  and\n",
    "      Plank, Barbara},\n",
    "    editor = \"Calzolari, Nicoletta  and\n",
    "      Kan, Min-Yen  and\n",
    "      Hoste, Veronique  and\n",
    "      Lenci, Alessandro  and\n",
    "      Sakti, Sakriani  and\n",
    "      Xue, Nianwen\",\n",
    "    booktitle = \"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)\",\n",
    "    month = may,\n",
    "    year = \"2024\",\n",
    "    address = \"Torino, Italia\",\n",
    "    publisher = \"ELRA and ICCL\",\n",
    "    url = \"https://aclanthology.org/2024.lrec-main.953\",\n",
    "    pages = \"10921--10938\",\n",
    "    abstract = \"Despite the success of the Universal Dependencies (UD) project exemplified by its impressive language breadth, there is still a lack in {`}within-language breadth{'}: most treebanks focus on standard languages. Even for German, the language with the most annotations in UD, so far no treebank exists for one of its language varieties spoken by over 10M people: Bavarian. To contribute to closing this gap, we present the first multi-dialect Bavarian treebank (MaiBaam) manually annotated with part-of-speech and syntactic dependency information in UD, covering multiple text genres (wiki, fiction, grammar examples, social, non-fiction). We highlight the morphosyntactic differences between the closely-related Bavarian and German and showcase the rich variability of speakers{'} orthographies. Our corpus includes 15k tokens, covering dialects from all Bavarian-speaking areas spanning three countries. We provide baseline parsing and POS tagging results, which are lower than results obtained on German and vary substantially between different graph-based parsers. To support further research on Bavarian syntax, we make our dataset, language-specific guidelines and code publicly available.\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rn45VNCQJ8lX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "collapsed_sections": [
    "cmnDDw75m-VN",
    "Qbi-1NiJnPyC"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
