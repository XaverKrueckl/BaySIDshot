{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A Notebook for Extended Auxiliary Task Experiments on Combinations of UD, NER and MLM Data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 24204,
     "status": "ok",
     "timestamp": 1719477557052,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "U-rXwrPTI-Mh",
    "outputId": "7b86a607-838e-4525-e510-77e2e36f4b6b"
   },
   "outputs": [],
   "source": [
    "# mount google drive for access to unpublished data and saving results!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# check if drive is present in root directory '/content'\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 29254,
     "status": "ok",
     "timestamp": 1719477586299,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "dcr3N0fjTUxa",
    "outputId": "7756b356-ecdd-4bdc-c79e-afe1fb0c08d8"
   },
   "outputs": [],
   "source": [
    "# prepare/clear drive directory\n",
    "%rm -r /content/BaySIDshot # should fail in initial call\n",
    "%cd /content\n",
    "# get a fresh clone of BaySIDshot repo with it's submodules\n",
    "! git clone https://github.com/XaverKrueckl/BaySIDshot.git --recurse-submodules\n",
    "# cd into BaySIDshot repo:\n",
    "%cd /content/BaySIDshot/\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8609,
     "status": "ok",
     "timestamp": 1719477594904,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "wJQLHAe8MbVS",
    "outputId": "158f3947-5204-4a41-a49e-e4fca473a794"
   },
   "outputs": [],
   "source": [
    "# prepare MLM data to use with machamp:\n",
    "# again move into BaySIDshot repo to be safe:\n",
    "\n",
    "! bash /content/BaySIDshot/scripts/prepare_mlm_data.sh\n",
    "\n",
    "# prepare UD data to use with machamp:\n",
    "%cd /content/BaySIDshot/\n",
    "\n",
    "! bash /content/BaySIDshot/scripts/prepare_ud_data.sh\n",
    "\n",
    "# data for NER is split!\n",
    "# Wiki train-test-dev data accessible via\n",
    "# /content/BaySIDshot/BarNER/data/BarNER-final/bar-wiki-*.tsv\n",
    "\n",
    "# Twitter train-test-dev data may not be published for public - saved in private repo\n",
    "# /content/BaySIDshot/BarNER_Twitter/bar-tweet-*.tsv\n",
    "\n",
    "# finally move into machamp to start training and predictions\n",
    "%cd /content/BaySIDshot/machamp\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k665fk8ZF419"
   },
   "source": [
    "## General Checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1719477594904,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "2RKo24KwfZZ3",
    "outputId": "fc299986-5f9f-4854-e6c2-37d8950dd0c2"
   },
   "outputs": [],
   "source": [
    "# make sure to have a GPU backend selected\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 128717,
     "status": "ok",
     "timestamp": 1719477723619,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "Er1X18YZaSOd",
    "outputId": "3c460726-6ff9-42b6-b7f9-d324f7cb12b1"
   },
   "outputs": [],
   "source": [
    "# install the required packages for machamp\n",
    "#! cat /content/BaySIDshot/machamp/README.md | grep \"requirements\"\n",
    "\n",
    "%cd /content/BaySIDshot/machamp\n",
    "! pip3 install --user -r /content/BaySIDshot/machamp/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10171,
     "status": "ok",
     "timestamp": 1719477733785,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "QyQgq3dNmZuP",
    "outputId": "94e3a320-7441-474c-dda5-7791db750c27"
   },
   "outputs": [],
   "source": [
    "# appends the directory /root/.local/bin to the existing PATH variable,\n",
    "# allowing executables located in that directory to be run from anywhere in the shell\n",
    "! export PATH=$PATH:/root/.local/bin\n",
    "\n",
    "# check if imports for machamp are there\n",
    "import tensorflow as tf\n",
    "# check the version\n",
    "print(tf.__version__)\n",
    "\n",
    "# check if basic system works\n",
    "! python3 /content/BaySIDshot/machamp/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare evaluation data:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!bash /content/BaySIDshot/scripts/prepare_evaldata_dialects.sh\n",
    "#!bash /content/BaySIDshot/scripts/prepare_evaldata_baseline.sh\n",
    "!bash /content/BaySIDshot/scripts/prepare_evaldata_alllangs.sh\n",
    "\n",
    "# if issues occur, use manually created gold set:\n",
    "# /content/BaySIDshot/manual_data/alllangs_eval_data # or just dialects_eval_data, etc.\n",
    "\n",
    "%cd /content/BaySIDshot/machamp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnhjVS_-KT_j"
   },
   "source": [
    "## MLM_NER_NLU Extended Mulit-Sequential Intermediate setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1719477734254,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "f7Qo79pqKif7",
    "outputId": "f6b442f3-90ff-4154-be54-5102a49cf140"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/mlm_x.json\n",
    "! cat /content/BaySIDshot/configs/ner_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7804875,
     "status": "ok",
     "timestamp": 1719493645742,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "Tf5O9FrRKuVb",
    "outputId": "def9dc41-2275-4541-a08b-ab6f0fae3090"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_mlm_ner_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mlm_x.json /content/BaySIDshot/configs/ner_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --sequential --device 0 --name mDeBERTa_exp4_mlm_ner_nlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wB8cJuxGK5Yu"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_mlm_ner_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72925,
     "status": "ok",
     "timestamp": 1719493734121,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "PgoXTrREKdI6",
    "outputId": "e526e4c6-f828-4a6d-8bee-c2bbae38cf60"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_mlm_ner_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "# other evaluation sets can be used here\n",
    "\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e-KIztas1AK"
   },
   "source": [
    "## MLMxNER_NLU Extended Sequential Intermediate Multitask setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 67,
     "status": "ok",
     "timestamp": 1719428012019,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "GdqyH43as0yQ",
    "outputId": "35e9ea2b-c642-4d3f-8f32-ed382e276933"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/mlm_ner_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2256900,
     "status": "ok",
     "timestamp": 1719435801764,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "tUK0DRQatXaa",
    "outputId": "ed856135-59ff-41be-e975-d87c69dc0add"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_mlmner_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mlm_ner_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --sequential --device 0 --name mDeBERTa_exp4_mlmner_nlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCwV22batv90"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_mlmner_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 73507,
     "status": "ok",
     "timestamp": 1719435887857,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "jxAkyvsos3Mc",
    "outputId": "19708175-3de3-4962-d475-67546b083824"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_mlmner_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrVrVufMc0ih"
   },
   "source": [
    "## MLMxNERxNLU Extended Multitask setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1719244373686,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "UJG-q9F3c3rY",
    "outputId": "1113b387-6077-4373-f4c9-e30977054ae0"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/mlm_ner_nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1777218,
     "status": "ok",
     "timestamp": 1719251997484,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "dxrPloL2c3ad",
    "outputId": "8f64e902-7505-46aa-f0e7-b531a0362c75"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_mlmnernlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mlm_ner_nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json  --device 0 --name mDeBERTa_exp4_mlmnernlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-HM7dhLmc3O6"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_mlmnernlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgrBiMC1c6G1"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_mlmnernlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK8dCdHLieRZ"
   },
   "source": [
    "## MLMxUD_NLU Sequential Intermediate Multitask setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1719464772536,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "ep11H77mihgW",
    "outputId": "6b9ebed5-310c-40ad-8973-d8fb282e4950"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/mlm_ud_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rWEKM6DimOz",
    "outputId": "cc0c0652-fcff-43d4-df93-01b7e207bd8b"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_mlmud_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mlm_ud_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --sequential --device 0 --name mDeBERTa_exp4_mlmud_nlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "N1b1C-shi5PC"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_mlmud_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4wpPlDJ5jhRh",
    "outputId": "9cb5f7fa-d54c-4b5f-9de3-d62acba062ce"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_mlmud_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPGT-z0UDZVP"
   },
   "source": [
    "## Extended MLMxUDxNERxNLU Multitask setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1719297684838,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "rfnMm7OqDa4e",
    "outputId": "6d413f76-97f6-4d24-c457-629e181b6514"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/mulm_ud_ner_nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2939821,
     "status": "ok",
     "timestamp": 1719313880362,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "lnV8OmI5Dqgx",
    "outputId": "768c836f-ead8-4408-bab5-ff5fe80e24c7"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_mlmudnernlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mulm_ud_ner_nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json  --device 0 --name mDeBERTa_exp4_mlmudnernlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ifex4kvBDz3T"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_mlmudnernlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71256,
     "status": "ok",
     "timestamp": 1719316173121,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "e3n3vPBHED4t",
    "outputId": "e345209a-4de3-4870-8409-40f6b35a1601"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_mlmudnernlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JGo3VlvVsdL"
   },
   "source": [
    "## UD_NER_NLU Extended Mulit-Sequential Intermediate setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 713,
     "status": "ok",
     "timestamp": 1719493770616,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "LSG-irtvV-Py",
    "outputId": "9596a19b-5914-4a4c-a203-91c0765ff5d4"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/ud_x.json\n",
    "! cat /content/BaySIDshot/configs/ner_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_vQZ8wWeYMn1",
    "outputId": "592fe95a-bff0-400c-c270-79826bf26661",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719509031498,
     "user_tz": -120,
     "elapsed": 81571,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    }
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_ud_ner_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/ud_x.json /content/BaySIDshot/configs/ner_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --sequential --device 0 --name mDeBERTa_exp4_ud_ner_nlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8WM1TEUYMcN"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_ud_ner_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USpaqHpcYAK1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719509109322,
     "user_tz": -120,
     "elapsed": 61584,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "c5b346b2-fec1-42e3-ac2c-52e6e6e4fd15"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_ud_ner_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZ2cFte_ss2v"
   },
   "source": [
    "## UDxNER_NLU Extended Sequential Intermediate Multitask setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1719327632168,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "WKqtrTf7s7gI",
    "outputId": "b9251ae1-0275-47a4-8a7e-a9a0f533183f"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/ud_ner_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 146545,
     "status": "ok",
     "timestamp": 1719334981022,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "8hSo7XpUtWxJ",
    "outputId": "1ecb2313-c537-4069-8478-296a62ca2edc"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_udner_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/ud_ner_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --sequential --device 0 --name mDeBERTa_exp4_udner_nlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6p2tvXBgtsXk"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_udner_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37250,
     "status": "ok",
     "timestamp": 1719335024109,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "AiOgrgNauJwv",
    "outputId": "45abf6ae-7125-46b8-bdd9-14bed30b580a"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_udner_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFL2LyXpRBjC"
   },
   "source": [
    "## UDxNERxNLU Extended Multitask Setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1719382804065,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "Ep39dLom-5Qu",
    "outputId": "eef05164-d3da-489a-8698-54cc03e92461"
   },
   "outputs": [],
   "source": [
    "# inspect configs to be used\n",
    "! cat /content/BaySIDshot/configs/ud_ner_nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3527919,
     "status": "ok",
     "timestamp": 1719389919739,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "g-IQ2moIuvx_",
    "outputId": "051725b6-1c9c-4afd-fc2b-2bcd585c5125"
   },
   "outputs": [],
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp4_udnernlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/ud_ner_nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json  --device 0 --name mDeBERTa_exp4_udnernlu_1234 --seed 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWg1Ea04J3qA"
   },
   "outputs": [],
   "source": [
    "# save logs dir with model and metrics to drive - change name of experiment accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp4_udnernlu_1234* /content/drive/MyDrive/Masterarbeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 59323,
     "status": "ok",
     "timestamp": 1719389987201,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "qfye40NkJ43_",
    "outputId": "6944fd76-de27-4100-fa0b-d3202e73fcf0"
   },
   "outputs": [],
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_udnernlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reference for _MaChAmp_ as well as UD, NER and MLM Data:\n",
    "\n",
    "```\n",
    "@inproceedings{van-der-goot-etal-2021-massive,\n",
    "    title = \"Massive Choice, Ample Tasks ({M}a{C}h{A}mp): A Toolkit for Multi-task Learning in {NLP}\",\n",
    "    author = {van der Goot, Rob  and\n",
    "      {\\\"U}st{\\\"u}n, Ahmet  and\n",
    "      Ramponi, Alan  and\n",
    "      Sharaf, Ibrahim  and\n",
    "      Plank, Barbara},\n",
    "    booktitle = \"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations\",\n",
    "    month = apr,\n",
    "    year = \"2021\",\n",
    "    address = \"Online\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2021.eacl-demos.22\",\n",
    "    doi = \"10.18653/v1/2021.eacl-demos.22\",\n",
    "    pages = \"176--197\",\n",
    "    abstract = \"Transfer learning, particularly approaches that combine multi-task learning with pre-trained contextualized embeddings and fine-tuning, have advanced the field of Natural Language Processing tremendously in recent years. In this paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized embeddings in multi-task settings. The benefits of MaChAmp are its flexible configuration options, and the support of a variety of natural language processing tasks in a uniform toolkit, from text classification and sequence labeling to dependency parsing, masked language modeling, and text generation.\",\n",
    "}\n",
    "@inproceedings{blaschke-etal-2024-maibaam,\n",
    "    title = \"{M}ai{B}aam: A Multi-Dialectal {B}avarian {U}niversal {D}ependency Treebank\",\n",
    "    author = {Blaschke, Verena  and\n",
    "      Kova{\\v{c}}i{\\'c}, Barbara  and\n",
    "      Peng, Siyao  and\n",
    "      Sch{\\\"u}tze, Hinrich  and\n",
    "      Plank, Barbara},\n",
    "    editor = \"Calzolari, Nicoletta  and\n",
    "      Kan, Min-Yen  and\n",
    "      Hoste, Veronique  and\n",
    "      Lenci, Alessandro  and\n",
    "      Sakti, Sakriani  and\n",
    "      Xue, Nianwen\",\n",
    "    booktitle = \"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)\",\n",
    "    month = may,\n",
    "    year = \"2024\",\n",
    "    address = \"Torino, Italia\",\n",
    "    publisher = \"ELRA and ICCL\",\n",
    "    url = \"https://aclanthology.org/2024.lrec-main.953\",\n",
    "    pages = \"10921--10938\",\n",
    "    abstract = \"Despite the success of the Universal Dependencies (UD) project exemplified by its impressive language breadth, there is still a lack in {`}within-language breadth{'}: most treebanks focus on standard languages. Even for German, the language with the most annotations in UD, so far no treebank exists for one of its language varieties spoken by over 10M people: Bavarian. To contribute to closing this gap, we present the first multi-dialect Bavarian treebank (MaiBaam) manually annotated with part-of-speech and syntactic dependency information in UD, covering multiple text genres (wiki, fiction, grammar examples, social, non-fiction). We highlight the morphosyntactic differences between the closely-related Bavarian and German and showcase the rich variability of speakers{'} orthographies. Our corpus includes 15k tokens, covering dialects from all Bavarian-speaking areas spanning three countries. We provide baseline parsing and POS tagging results, which are lower than results obtained on German and vary substantially between different graph-based parsers. To support further research on Bavarian syntax, we make our dataset, language-specific guidelines and code publicly available.\",\n",
    "}\n",
    "@inproceedings{peng-etal-2024-sebastian,\n",
    "    title = \"Sebastian, Basti, Wastl?! Recognizing Named Entities in {B}avarian Dialectal Data\",\n",
    "    author = \"Peng, Siyao  and\n",
    "      Sun, Zihang  and\n",
    "      Shan, Huangyan  and\n",
    "      Kolm, Marie  and\n",
    "      Blaschke, Verena  and\n",
    "      Artemova, Ekaterina  and\n",
    "      Plank, Barbara\",\n",
    "    editor = \"Calzolari, Nicoletta  and\n",
    "      Kan, Min-Yen  and\n",
    "      Hoste, Veronique  and\n",
    "      Lenci, Alessandro  and\n",
    "      Sakti, Sakriani  and\n",
    "      Xue, Nianwen\",\n",
    "    booktitle = \"Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)\",\n",
    "    month = may,\n",
    "    year = \"2024\",\n",
    "    address = \"Torino, Italia\",\n",
    "    publisher = \"ELRA and ICCL\",\n",
    "    url = \"https://aclanthology.org/2024.lrec-main.1262\",\n",
    "    pages = \"14478--14493\",\n",
    "    abstract = \"Named Entity Recognition (NER) is a fundamental task to extract key information from texts, but annotated resources are scarce for dialects. This paper introduces the first dialectal NER dataset for German, BarNER, with 161K tokens annotated on Bavarian Wikipedia articles (bar-wiki) and tweets (bar-tweet), using a schema adapted from German CoNLL 2006 and GermEval. The Bavarian dialect differs from standard German in lexical distribution, syntactic construction, and entity information. We conduct in-domain, cross-domain, sequential, and joint experiments on two Bavarian and three German corpora and present the first comprehensive NER results on Bavarian. Incorporating knowledge from the larger German NER (sub-)datasets notably improves on bar-wiki and moderately on bar-tweet. Inversely, training first on Bavarian contributes slightly to the seminal German CoNLL 2006 corpus. Moreover, with gold dialect labels on Bavarian tweets, we assess multi-task learning between five NER and two Bavarian-German dialect identification tasks and achieve NER SOTA on bar-wiki. We substantiate the necessity of our low-resource BarNER corpus and the importance of diversity in dialects, genres, and topics in enhancing model performance.\",\n",
    "}\n",
    "@inproceedings{artemova-plank-2023-low,\n",
    "    title = \"Low-resource Bilingual Dialect Lexicon Induction with Large Language Models\",\n",
    "    author = \"Artemova, Ekaterina  and Plank, Barbara\",\n",
    "    booktitle = \"Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa 2023) (NoDaLiDa)\",\n",
    "    year = \"2023\",\n",
    "}\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rn45VNCQJ8lX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "lnhjVS_-KT_j",
    "NXkHZIZ0KdxR",
    "4e-KIztas1AK",
    "syQy_eXts3k0",
    "zrVrVufMc0ih",
    "64qzAcq6c4OR",
    "XK8dCdHLieRZ",
    "OOs3RxVVifp0",
    "OD4qTUeDD97-",
    "bZ2cFte_ss2v",
    "RUMXvTPrszS3",
    "nFL2LyXpRBjC",
    "1is3uDrqQ-pW",
    "_E-bDbwKVZR1"
   ],
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
