{
  "transformer_model": "FacebookAI/xlm-roberta-base",
  "transformer_model_dim": 768,
  "reset_transformer_model": false,
  "random_seed": 8446,
  "numpy_seed": 1337,
  "pytorch_seed": 133,
  "default_dec_dataset_embeds_dim": 12,

  "encoder": {
    "dropout": 0.3,
    "max_input_length": 128,
    "update_weights_encoder": true
  },

  "decoders": {
    "default_decoder": {
      "loss_weight": 1.0,
      "metric": "accuracy",
      "topn": 1,
      "layers_to_use": [-1]
    },
    "classification": {
      "metric": "accuracy"
    },
    "dependency": {
      "arc_representation_dim": 768,
      "tag_representation_dim": 256,
      "metric": "las"
    },
    "mlm": {
      "metric": "perplexity"
    },
    "multiclas": {
      "metric": "multi_acc",
      "threshold": 0.7
    },
    "multiseq": {
      "metric": "multi_acc",
      "threshold": 0.7
    },
    "regression": {
      "metric": "avg_dist"
    },
    "seq": {
      "metric": "span_f1"
    },
    "seq_bio": {
      "metric": "span_f1"
    },
    "string2string": {
      "metric": "accuracy"
    },
    "tok": {
      "pre_split": true
    }
  },

  "batching": {
    "max_tokens": 1024,
    "shuffle": true,
    "batch_size": 32,
    "sort_by_size": true,
    "diverse": false,
    "sampling_smoothing": 1.0
  },

  "training": {
        "keep_top_n": 1,
        "checkpointer": {
            "num_serialized_models_to_keep": 1
        },
        "use_amp": true,
        "grad_norm": 1,
        "learning_rate_scheduler": {
            "cut_frac": 0.2,
            "decay_factor": 0.38,
            "discriminative_fine_tuning": true,
            "gradual_unfreezing": true
        },
        "num_epochs": 20,
        "optimizer": {
            "betas": [0.9, 0.99],
            "correct_bias": false,
            "lr": 0.0001,
            "weight_decay": 0.01
        }
    }
}
