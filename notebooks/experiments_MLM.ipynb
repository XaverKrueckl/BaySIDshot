{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVcOCrPFZyNq"
   },
   "source": [
    "# A Notebook for Basic Auxiliary Task Experiments on MLM Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 28806,
     "status": "ok",
     "timestamp": 1718261317070,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "U-rXwrPTI-Mh",
    "outputId": "4254f053-958b-4b18-fd74-a94c5441ea07"
   },
   "outputs": [],
   "source": [
    "# mount google drive for access to unpublished data and saving results!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# check if drive is present in root directory '/content'\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 41980,
     "status": "ok",
     "timestamp": 1718261359044,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "dcr3N0fjTUxa",
    "outputId": "1b78d487-4367-49ea-b397-ce35cc09d3f8"
   },
   "outputs": [],
   "source": [
    "# prepare/clear drive directory\n",
    "%rm -r /content/BaySIDshot # should fail in initial call\n",
    "%cd /content\n",
    "# get a fresh clone of BaySIDshot repo with it's submodules\n",
    "! git clone https://github.com/XaverKrueckl/BaySIDshot.git --recurse-submodules\n",
    "# cd into BaySIDshot repo:\n",
    "%cd /content/BaySIDshot/\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# prepare MLM data to use with machamp:\n",
    "# again move into BaySIDshot repo to be safe:\n",
    "\n",
    "! bash /content/BaySIDshot/scripts/prepare_mlm_data.sh\n",
    "\n",
    "# finally move into machamp to start training and predictions\n",
    "%cd /content/BaySIDshot/machamp\n",
    "%ls -l\n",
    "%pwd"
   ],
   "metadata": {
    "id": "wJQLHAe8MbVS",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 888
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718261368884,
     "user_tz": -120,
     "elapsed": 9846,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "0b995730-3f56-4a5f-9701-0cf881c00dae"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Checks:"
   ],
   "metadata": {
    "id": "Pb3m-8_sBDGw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1718261368885,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "2RKo24KwfZZ3",
    "outputId": "8cb10d20-aec6-452e-e5f0-50c24bc90a26"
   },
   "outputs": [],
   "source": [
    "# make sure to have a GPU backend selected\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 132403,
     "status": "ok",
     "timestamp": 1718261501274,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "Er1X18YZaSOd",
    "outputId": "c0b4187a-450e-4e2d-eaf6-d936a539b046"
   },
   "outputs": [],
   "source": [
    "# install the required packages for machamp\n",
    "#! cat /content/BaySIDshot/machamp/README.md | grep \"requirements\"\n",
    "\n",
    "%cd /content/BaySIDshot/machamp\n",
    "! pip3 install --user -r /content/BaySIDshot/machamp/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10965,
     "status": "ok",
     "timestamp": 1718261512233,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     },
     "user_tz": -120
    },
    "id": "QyQgq3dNmZuP",
    "outputId": "1e0d23fc-6f40-4aeb-bbea-622cfc9a0731"
   },
   "outputs": [],
   "source": [
    "# appends the directory /root/.local/bin to the existing PATH variable,\n",
    "# allowing executables located in that directory to be run from anywhere in the shell\n",
    "! export PATH=$PATH:/root/.local/bin\n",
    "\n",
    "# check if imports for machamp are there\n",
    "import tensorflow as tf\n",
    "# check the version\n",
    "print(tf.__version__)\n",
    "\n",
    "# check if basic system works\n",
    "! python3 /content/BaySIDshot/machamp/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare evaluation data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!bash /content/BaySIDshot/scripts/prepare_evaldata_dialects.sh\n",
    "#!bash /content/BaySIDshot/scripts/prepare_evaldata_baseline.sh\n",
    "!bash /content/BaySIDshot/scripts/prepare_evaldata_alllangs.sh\n",
    "\n",
    "# if issues occur, use manually created gold set:\n",
    "# /content/BaySIDshot/manual_data/alllangs_eval_data # or just dialects_eval_data, etc.\n",
    "\n",
    "%cd /content/BaySIDshot/machamp"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Continuous Pre-Training MLMxNLU Multitask setting:"
   ],
   "metadata": {
    "id": "XFWH4ScuZES6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# inspect the config to be used\n",
    "! cat /content/BaySIDshot/configs/mlm_nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "j9e7nwxbZN5_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718261512234,
     "user_tz": -120,
     "elapsed": 8,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "ec9a2c72-0f84-4c65-b464-1c018d6c9e60"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp3_mlmnlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mlm_nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --device 0 --name mDeBERTa_exp3_mlmnlu_1234 --seed 1234"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYpwjIxSZOtX",
    "outputId": "203429e4-c6d1-406c-9471-1d0cc4c32d53",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718279224796,
     "user_tz": -120,
     "elapsed": 2313282,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# save logs dir with model and metrics to drive - change name of logs dir accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp3_mlmnlu_1234* /content/drive/MyDrive/Masterarbeit"
   ],
   "metadata": {
    "id": "APkYeP8HZQ5I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp3_mlmnlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ],
   "metadata": {
    "id": "HNfO2IRtbKDf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718279301796,
     "user_tz": -120,
     "elapsed": 71088,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "8a8d417b-949b-40ad-a5c8-66662bf5eec0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic Sequential Intermediate Continuous Pre-Training MLM_NLU setting:"
   ],
   "metadata": {
    "id": "1is3uDrqQ-pW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# inspect the config to be used\n",
    "! cat /content/BaySIDshot/configs/mlm_x.json\n",
    "! cat /content/BaySIDshot/configs/nlu_x.json\n",
    "\n",
    "# inspect params to be used\n",
    "! cat /content/BaySIDshot/configs/params_mdeberta.json"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JL5R-A5Qt9Rf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718279318364,
     "user_tz": -120,
     "elapsed": 608,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "2f71e47e-d4fa-4cf4-d1f5-7e4b6b4baa3c",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train experiment continuous mlm pretraining of mDeBERTa\n",
    "# make sure be in ../machamp or use direct path as below\n",
    "# set name of experiment / logs directory! --name mDeBERTa_exp3_mlm_nlu_SEED\n",
    "# with respective random seed that should be used --seed 1234 e.g.\n",
    "\n",
    "\n",
    "! python3 /content/BaySIDshot/machamp/train.py --dataset_configs /content/BaySIDshot/configs/mlm_x.json /content/BaySIDshot/configs/nlu_x.json --parameters /content/BaySIDshot/configs/params_mdeberta.json --sequential --device 0 --name mDeBERTa_exp3_mlm_nlu_1234 --seed 1234"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oaNTUQUuJ-L",
    "outputId": "3678aed1-81a6-44b7-be2d-b113d27777a3",
    "collapsed": true,
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718285154673,
     "user_tz": -120,
     "elapsed": 2887504,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# save logs dir with model and metrics to drive - change name of logs dir accordingly!\n",
    "\n",
    "! cp -R /content/BaySIDshot/machamp/logs/mDeBERTa_exp3_mlm_nlu_1234* /content/drive/MyDrive/Masterarbeit"
   ],
   "metadata": {
    "id": "WdlT2lBJuJds",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718285164087,
     "user_tz": -120,
     "elapsed": 9422,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# SET and get path(s) to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp3_mlm_nlu_1234*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "#eval_dir = \"/content/BaySIDshot/manual_data/alllangs_eval_data\"\n",
    "eval_dir = \"/content/BaySIDshot/alllangs_eval_data\"\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ],
   "metadata": {
    "id": "wq5vZ4PyukVG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718285240577,
     "user_tz": -120,
     "elapsed": 73816,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "a49aef86-8ee8-4568-a9f1-59e11f82c5d9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhcUQ7_A1y0t"
   },
   "source": [
    "### Reference for _MaChAmp_ and MLM Data:\n",
    "\n",
    "```\n",
    "@inproceedings{van-der-goot-etal-2021-massive,\n",
    "    title = \"Massive Choice, Ample Tasks ({M}a{C}h{A}mp): A Toolkit for Multi-task Learning in {NLP}\",\n",
    "    author = {van der Goot, Rob  and\n",
    "      {\\\"U}st{\\\"u}n, Ahmet  and\n",
    "      Ramponi, Alan  and\n",
    "      Sharaf, Ibrahim  and\n",
    "      Plank, Barbara},\n",
    "    booktitle = \"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations\",\n",
    "    month = apr,\n",
    "    year = \"2021\",\n",
    "    address = \"Online\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2021.eacl-demos.22\",\n",
    "    doi = \"10.18653/v1/2021.eacl-demos.22\",\n",
    "    pages = \"176--197\",\n",
    "    abstract = \"Transfer learning, particularly approaches that combine multi-task learning with pre-trained contextualized embeddings and fine-tuning, have advanced the field of Natural Language Processing tremendously in recent years. In this paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized embeddings in multi-task settings. The benefits of MaChAmp are its flexible configuration options, and the support of a variety of natural language processing tasks in a uniform toolkit, from text classification and sequence labeling to dependency parsing, masked language modeling, and text generation.\",\n",
    "}\n",
    "@inproceedings{artemova-plank-2023-low,\n",
    "    title = \"Low-resource Bilingual Dialect Lexicon Induction with Large Language Models\",\n",
    "    author = \"Artemova, Ekaterina  and Plank, Barbara\",\n",
    "    booktitle = \"Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa 2023) (NoDaLiDa)\",\n",
    "    year = \"2023\",\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "collapsed_sections": [
    "nFL2LyXpRBjC",
    "8lRJ2Ptqt6aH",
    "I0xe1kemMpu3",
    "KvFLXs8AuSmB"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
