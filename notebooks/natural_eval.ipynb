{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVcOCrPFZyNq"
   },
   "source": [
    "# A Notebook for predicting already fine-tuned MaChAmp Models on Natural Bavarian Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dcr3N0fjTUxa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828654827,
     "user_tz": -120,
     "elapsed": 16425,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "6b8789c6-7568-4f13-8b67-ba4c0e084fb5"
   },
   "outputs": [],
   "source": [
    "# mount google drive for access to unpublished data and saving results!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# check if drive is present in root directory '/content'\n",
    "%ls -l\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "## prepare/clear drive directory\n",
    "%rm -r /content/BaySIDshot # should fail in initial call\n",
    "%cd /content\n",
    "# get a fresh clone of BaySIDshot repo with it's submodules\n",
    "! git clone https://github.com/XaverKrueckl/BaySIDshot.git --recurse-submodules\n",
    "# cd into BaySIDshot repo:\n",
    "%cd /content/BaySIDshot/\n",
    "%ls -l\n",
    "%pwd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6dub2nXXopwe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828697253,
     "user_tz": -120,
     "elapsed": 42437,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "7dd0401c-c19e-4cd5-a4ee-6b2bf2a9819f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Checks:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make sure to have a GPU backend selected\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RKo24KwfZZ3",
    "outputId": "2703b9b3-ce0d-4f36-f4a0-89f27fc416a7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828697658,
     "user_tz": -120,
     "elapsed": 447,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kf7GD5BaBvI",
    "outputId": "77d71a74-62c4-40a8-994e-5e83097ec54f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828842205,
     "user_tz": -120,
     "elapsed": 144569,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    }
   },
   "outputs": [],
   "source": [
    "# install the required packages for machamp\n",
    "#! cat /content/BaySIDshot/machamp/README.md | grep \"requirements\"\n",
    "\n",
    "%cd /content/BaySIDshot/machamp\n",
    "\n",
    "! pip3 install --user -r /content/BaySIDshot/machamp/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QyQgq3dNmZuP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828860742,
     "user_tz": -120,
     "elapsed": 18578,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "871a6d18-2cbd-4f59-e3ea-93a5871c784b"
   },
   "outputs": [],
   "source": [
    "# appends the directory /root/.local/bin to the existing PATH variable,\n",
    "# allowing executables located in that directory to be run from anywhere in the shell\n",
    "! export PATH=$PATH:/root/.local/bin\n",
    "\n",
    "# check if imports for machamp are there\n",
    "import tensorflow as tf\n",
    "# check the version\n",
    "print(tf.__version__)\n",
    "\n",
    "# check if basic system works\n",
    "! python3 /content/BaySIDshot/machamp/train.py"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# preparing prediction data:\n",
    "\n",
    "!bash /content/BaySIDshot/scripts/prepare_evaldata_natural.sh\n",
    "!ls -l /content/BaySIDshot/natural_eval_data\n",
    "%cd /content/BaySIDshot/machamp"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcSnvDn42uJp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828861196,
     "user_tz": -120,
     "elapsed": 475,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "f1d33711-c305-4b30-fc8e-31c1e8c4f207"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# get path to the final model\n",
    "# last line with text in model_path has model path to nlu model\n",
    "# (if nlu config was set as last one when sequential/intermediate training)\n",
    "# example with a path used in this master thesis:\n",
    "! ls -d /content/drive/MyDrive/Masterarbeit/mDeBERTa_exp4_mlmner_nlu_8446*/*/model_* > model_path.txt\n",
    "\n",
    "import os\n",
    "\n",
    "with open('model_path.txt', 'r') as file:\n",
    "  lines = file.readlines()\n",
    "  # get the path to the final model (maily if sequential experiment)\n",
    "  model_line = [line.strip() for line in lines if line.strip()][-1]\n",
    "  model_line = model_line.strip()\n",
    "  print(\"Evaluating Model: \", model_line)\n",
    "  if '/' in model_line:\n",
    "    # just to show the parts of the path:\n",
    "    parts = model_line.split('/')\n",
    "    # get all the necessary path parts:\n",
    "    model = model_line.split('/')[7]\n",
    "    time = model_line.split('/')[6]\n",
    "    experiment_name = model_line.split('/')[5]\n",
    "    if experiment_name.split(\".\"):\n",
    "      experiment_name_cleaned = experiment_name.split(\".\")[0]\n",
    "    save_dir = model_line.split('/')[:5]\n",
    "    base_save_dir = '/'.join(save_dir)\n",
    "  else:\n",
    "    raise ValueError(\"No valid model path\")\n",
    "\n",
    "\n",
    "eval_dir = \"/content/BaySIDshot/natural_eval_data\"\n",
    "\n",
    "\n",
    "with open('script.sh', 'w') as file:\n",
    "    # create predictions folder in directory where model is saved:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/{experiment_name}/{time}/natural_predictions_{experiment_name_cleaned}\\n\")\n",
    "    # prepare prediction files order\n",
    "    file_list = []\n",
    "    for filename in os.listdir(eval_dir):\n",
    "        if filename.endswith('test.conll'): # do not use when also using valid files is desired\n",
    "          # path to goldfile:\n",
    "          goldfile = eval_dir + \"/\" + filename\n",
    "          # path to outfile\n",
    "          outfile = base_save_dir + \"/\" + experiment_name + \"/\" + time + \"/natural_predictions_\" + experiment_name_cleaned + \"/\" + filename + \".out\"\n",
    "          # append goldfile outfile \"pairs\" to filelist for prediction command\n",
    "          file_list.append(str(goldfile))\n",
    "          file_list.append(str(outfile))\n",
    "    file_list_string = ' '.join(file_list)\n",
    "    # prediction call for all files in test dir\n",
    "    # also adds the specific dataset for which prediction should be done - necessary in multitask setting, else possible to also append\n",
    "    file.write(f\"! python3 predict.py {model_line} {file_list_string} --device 0 --dataset NLU\\n\")\n",
    "    # dir eval call to get all metrics and save output as json file:\n",
    "    file.write(f\"! python3 /content/BaySIDshot/scripts/dir_eval_out.py {eval_dir} {base_save_dir}/{experiment_name}/{time}/natural_predictions_{experiment_name_cleaned}\\n\")\n",
    "    # copy json output also to predictions dir:\n",
    "    file.write(f\"! mkdir -p {base_save_dir}/results\\n\")\n",
    "    file.write(f\"! cp /content/BaySIDshot/results/* {base_save_dir}/results\\n\")\n",
    "\n",
    "print(\"Prediction Script successfully generated!\")\n",
    "\n",
    "# runs predictions:\n",
    "! bash script.sh\n",
    "# and removes scripts:\n",
    "! rm script.sh\n",
    "! rm model_path.txt"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mScl8pX4AsS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1719828921272,
     "user_tz": -120,
     "elapsed": 60097,
     "user": {
      "displayName": "Xaver Krueckl",
      "userId": "04994225532745810101"
     }
    },
    "outputId": "4cc2a9fa-b563-4be7-c3be-3a24a8af8051",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhcUQ7_A1y0t"
   },
   "source": [
    "### Reference for _MaChAmp_ and Bavarian Natural Evaluation Data:\n",
    "\n",
    "```\n",
    "@inproceedings{van-der-goot-etal-2021-massive,\n",
    "    title = \"Massive Choice, Ample Tasks ({M}a{C}h{A}mp): A Toolkit for Multi-task Learning in {NLP}\",\n",
    "    author = {van der Goot, Rob  and\n",
    "      {\\\"U}st{\\\"u}n, Ahmet  and\n",
    "      Ramponi, Alan  and\n",
    "      Sharaf, Ibrahim  and\n",
    "      Plank, Barbara},\n",
    "    booktitle = \"Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations\",\n",
    "    month = apr,\n",
    "    year = \"2021\",\n",
    "    address = \"Online\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2021.eacl-demos.22\",\n",
    "    doi = \"10.18653/v1/2021.eacl-demos.22\",\n",
    "    pages = \"176--197\",\n",
    "    abstract = \"Transfer learning, particularly approaches that combine multi-task learning with pre-trained contextualized embeddings and fine-tuning, have advanced the field of Natural Language Processing tremendously in recent years. In this paper we present MaChAmp, a toolkit for easy fine-tuning of contextualized embeddings in multi-task settings. The benefits of MaChAmp are its flexible configuration options, and the support of a variety of natural language processing tasks in a uniform toolkit, from text classification and sequence labeling to dependency parsing, masked language modeling, and text generation.\",\n",
    "}\n",
    "@inproceedings{Winkler2024,\n",
    "  title = \"Slot and Intent Detection Resources for {B}avarian and {L}ithuanian: Assessing Translations vs Natural Queries to Digital Assistants\",\n",
    "  author = \"Winkler, Miriam and Juozapaityte, Virginija and van der Goot, Rob and Plank, Barbara\",\n",
    "  booktitle = \"Proceedings of The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation\",\n",
    "  year = \"2024\",\n",
    "  publisher = \"Association for Computational Linguistics\",\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
