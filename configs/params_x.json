{

  // set different transformer models here:
  "transformer_model": "google-bert/bert-base-multilingual-cased",
  // "transformer_model": "FacebookAI/xlm-roberta-base",
  // "transformer_model": "microsoft/mdeberta-v3-base",
  // "transformer_model": "deepset/gbert-base",  // used "google-bert/bert-base-german-cased""deepset/gbert-base" but this is older
  // set transformer_model_dim somewhere?
  "reset_transformer_model": false,
  "random_seed": 8446, // change here was not immanent - set a different random seed as command line argument
  "numpy_seed": 1337,
  "pytorch_seed": 133,
  "default_dec_dataset_embeds_dim": 12,
  "encoder": {
    "dropout": 0.3, // adapted to xSID appendix
    "max_input_length": 128,
    "update_weights_encoder": true
  },

  "decoders": {

    "default_decoder": {
      "loss_weight": 1.0,
      "metric": "accuracy",
      "topn": 1,
      "layers_to_use": [-1]
    },
    "classification": {
      "metric": "accuracy" // set this here as default metric - was not present in default param file
    },
    "dependency": {
      "arc_representation_dim": 768,
      "tag_representation_dim": 256,
      "metric": "las"
    },
    "mlm": {
      "metric": "perplexity"
    },
    "multiclas": {
      "metric": "multi_acc",
      "threshold": 0.7
    },
    "multiseq": {
      "metric": "multi_acc",
      "threshold": 0.7
    },
    "regression": {
      "metric": "avg_dist"
    },
    "seq": {
      "metric": "span_f1" // set this here as default metric - was not present in default param file
    },
    "seq_bio": {
      "metric": "span_f1"
    },
    "string2string": {
    },
    "tok": {
      "pre_split": true
    }
  },

  "batching": {
    "max_tokens": 1024,
    "shuffle": true,
    "batch_size": 32,
    "sort_by_size": true,
    "diverse": false,
    "sampling_smoothing": 1.0 // 1.0 == original size, 0.0==all equal
  },

  "training": {
    "keep_top_n": 1,
    "learning_rate_scheduler": {
      //"type": "slanted_triangular", // when trying to adapt to xSID appendix -
      // SlantedTriangular.__init__() got an unexpected keyword argument 'type' - was commented out in default
      "cut_frac": 0.2, // adapted to xSID appendix
      "decay_factor": 0.38,
      "discriminative_fine_tuning": true,
      "gradual_unfreezing": true
    },

    "num_epochs": 20,

    "optimizer": {
      //"type": "adamw", // when trying to adapt to xSID appendix - AdamW.__init__() got an unexpected keyword argument 'type'
      "betas": [0.9, 0.99],
      "lr": 0.001,  // adapted to xSID appendix
      "weight_decay": 0.01,
      //"correct_bias": false,
      //"patience": 5, // disabled, because slanted_triangular changes the lr dynamically
    },

  },

}

